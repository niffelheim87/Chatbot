{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pickle\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "import json\n",
    "import random\n",
    "\n",
    "# Initialize the lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('chatbot_model.h5')\n",
    "\n",
    "# Load intents file\n",
    "intents = json.loads(open('intents.json').read())\n",
    "\n",
    "# Load words and classes from pickle files\n",
    "words = pickle.load(open('words.pkl', 'rb'))\n",
    "classes = pickle.load(open('classes.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up_sentence(sentence):\n",
    "    # Tokenize the pattern - split words into an array\n",
    "    sentence_words = nltk.word_tokenize(sentence)\n",
    "    \n",
    "    # Lemmatize each word - create the base form for each word\n",
    "    sentence_words = [lemmatizer.lemmatize(word.lower()) for word in sentence_words]\n",
    "    return sentence_words\n",
    "\n",
    "def bow(sentence, words, show_details=True):\n",
    "    \"\"\"\n",
    "    Return a bag of words array: 0 or 1 for each word in the bag \n",
    "    that exists in the sentence.\n",
    "    \"\"\"\n",
    "    # Tokenize the pattern\n",
    "    sentence_words = clean_up_sentence(sentence)\n",
    "    \n",
    "    # Bag of words - matrix of N words, vocabulary matrix\n",
    "    bag = [0] * len(words)\n",
    "    for s in sentence_words:\n",
    "        for i, w in enumerate(words):\n",
    "            if w == s:\n",
    "                # Assign 1 if the current word is in the vocabulary position\n",
    "                bag[i] = 1\n",
    "                if show_details:\n",
    "                    print(f\"found in bag: {w}\")\n",
    "    return np.array(bag)\n",
    "\n",
    "def predict_class(sentence, model):\n",
    "    \"\"\"\n",
    "    Predict the class of the given sentence using the trained model.\n",
    "    \"\"\"\n",
    "    # Filter out predictions below a threshold\n",
    "    p = bow(sentence, words, show_details=False)\n",
    "    res = model.predict(np.array([p]))[0]\n",
    "    ERROR_THRESHOLD = 0.25\n",
    "    results = [[i, r] for i, r in enumerate(res) if r > ERROR_THRESHOLD]\n",
    "    \n",
    "    # Sort by strength of probability\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return_list = []\n",
    "    \n",
    "    for r in results:\n",
    "        return_list.append({\"intent\": classes[r[0]], \"probability\": str(r[1])})\n",
    "    return return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getResponse(ints, intents_json):\n",
    "    \"\"\"\n",
    "    Retrieve a response based on the predicted intent.\n",
    "    \n",
    "    Parameters:\n",
    "    - ints: List of intents with probabilities returned by `predict_class`.\n",
    "    - intents_json: JSON object containing all intents and their responses.\n",
    "    \n",
    "    Returns:\n",
    "    - A randomly selected response corresponding to the predicted intent.\n",
    "    \"\"\"\n",
    "    tag = ints[0]['intent']  # Get the top predicted intent\n",
    "    list_of_intents = intents_json['intents']\n",
    "    \n",
    "    for i in list_of_intents:\n",
    "        if i['tag'] == tag:  # Match the intent tag\n",
    "            result = random.choice(i['responses'])  # Select a random response\n",
    "            break\n",
    "    return result\n",
    "\n",
    "def chatbot_response(text):\n",
    "    \"\"\"\n",
    "    Generate a chatbot response for the given input text.\n",
    "    \n",
    "    Parameters:\n",
    "    - text: User input string.\n",
    "    \n",
    "    Returns:\n",
    "    - A string response from the chatbot.\n",
    "    \"\"\"\n",
    "    ints = predict_class(text, model)  # Predict the intent\n",
    "    res = getResponse(ints, intents)  # Get the corresponding response\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python312\\Lib\\tkinter\\__init__.py\", line 1968, in __call__\n",
      "    return self.func(*args)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\NIFFELHEIM\\AppData\\Local\\Temp\\ipykernel_936\\4172229907.py\", line 21, in send\n",
      "    res = chatbot_response(msg)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\NIFFELHEIM\\AppData\\Local\\Temp\\ipykernel_936\\3101043445.py\", line 31, in chatbot_response\n",
      "    ints = predict_class(text, model)  # Predict the intent\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\NIFFELHEIM\\AppData\\Local\\Temp\\ipykernel_936\\1212367674.py\", line 33, in predict_class\n",
      "    p = bow(sentence, words, show_details=False)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\NIFFELHEIM\\AppData\\Local\\Temp\\ipykernel_936\\1212367674.py\", line 15, in bow\n",
      "    sentence_words = clean_up_sentence(sentence)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\NIFFELHEIM\\AppData\\Local\\Temp\\ipykernel_936\\1212367674.py\", line 3, in clean_up_sentence\n",
      "    sentence_words = nltk.word_tokenize(sentence)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python312\\Lib\\site-packages\\nltk\\tokenize\\__init__.py\", line 142, in word_tokenize\n",
      "    sentences = [text] if preserve_line else sent_tokenize(text, language)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python312\\Lib\\site-packages\\nltk\\tokenize\\__init__.py\", line 119, in sent_tokenize\n",
      "    tokenizer = _get_punkt_tokenizer(language)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python312\\Lib\\site-packages\\nltk\\tokenize\\__init__.py\", line 105, in _get_punkt_tokenizer\n",
      "    return PunktTokenizer(language)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python312\\Lib\\site-packages\\nltk\\tokenize\\punkt.py\", line 1744, in __init__\n",
      "    self.load_lang(lang)\n",
      "  File \"c:\\Python312\\Lib\\site-packages\\nltk\\tokenize\\punkt.py\", line 1749, in load_lang\n",
      "    lang_dir = find(f\"tokenizers/punkt_tab/{lang}/\")\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python312\\Lib\\site-packages\\nltk\\data.py\", line 579, in find\n",
      "    raise LookupError(resource_not_found)\n",
      "LookupError: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\NIFFELHEIM/nltk_data'\n",
      "    - 'c:\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\NIFFELHEIM\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tkinter\n",
    "from tkinter import *\n",
    "\n",
    "def send():\n",
    "    \"\"\"\n",
    "    Handles the sending of a message from the user and displaying the bot's response.\n",
    "    \"\"\"\n",
    "    # Get user input from EntryBox\n",
    "    msg = EntryBox.get(\"1.0\", 'end-1c').strip()\n",
    "    EntryBox.delete(\"0.0\", END)\n",
    "    \n",
    "    if msg != '':\n",
    "        # Enable ChatLog for editing\n",
    "        ChatLog.config(state=NORMAL)\n",
    "        \n",
    "        # Insert user's message into the chat window\n",
    "        ChatLog.insert(END, \"You: \" + msg + '\\n\\n')\n",
    "        ChatLog.config(foreground=\"#442265\", font=(\"Verdana\", 12))\n",
    "        \n",
    "        # Get bot response and insert it into the chat window\n",
    "        res = chatbot_response(msg)\n",
    "        ChatLog.insert(END, \"Bot: \" + res + '\\n\\n')\n",
    "        \n",
    "        # Disable ChatLog to prevent editing and scroll to the end\n",
    "        ChatLog.config(state=DISABLED)\n",
    "        ChatLog.yview(END)\n",
    "\n",
    "# Initialize the main Tkinter window\n",
    "base = Tk()\n",
    "base.title(\"Chatbot\")\n",
    "base.geometry(\"400x500\")\n",
    "base.resizable(width=FALSE, height=FALSE)\n",
    "\n",
    "# Create ChatLog - a text widget to display conversation\n",
    "ChatLog = Text(base, bd=0, bg=\"white\", height=\"8\", width=\"50\", font=\"Arial\")\n",
    "ChatLog.config(state=DISABLED)\n",
    "\n",
    "# Create a scrollbar and bind it to ChatLog\n",
    "scrollbar = Scrollbar(base, command=ChatLog.yview, cursor=\"heart\")\n",
    "ChatLog['yscrollcommand'] = scrollbar.set\n",
    "\n",
    "# Create Send Button\n",
    "SendButton = Button(base, font=(\"Verdana\", 12, 'bold'), text=\"Send\", width=\"12\", height=5,\n",
    "                    bd=0, bg=\"#32de97\", activebackground=\"#3c9d9b\", fg='#ffffff', command=send)\n",
    "\n",
    "# Create EntryBox - a text widget for user to type messages\n",
    "EntryBox = Text(base, bd=0, bg=\"white\", width=\"29\", height=\"5\", font=\"Arial\")\n",
    "# Uncomment the line below to enable sending messages with the Enter key\n",
    "# EntryBox.bind(\"<Return>\", send)\n",
    "\n",
    "# Place all components on the window\n",
    "scrollbar.place(x=376, y=6, height=386)\n",
    "ChatLog.place(x=6, y=6, height=386, width=370)\n",
    "EntryBox.place(x=128, y=401, height=90, width=265)\n",
    "SendButton.place(x=6, y=401, height=90)\n",
    "\n",
    "# Start the Tkinter event loop\n",
    "base.mainloop()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
